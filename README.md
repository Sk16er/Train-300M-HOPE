
---

# ‚≠ê PART 1 ‚Äî Create your AWS GPU machine (EC2)

### 1Ô∏è‚É£ Go to AWS Console

[https://console.aws.amazon.com/](https://console.aws.amazon.com/)

### 2Ô∏è‚É£ Go to:

**EC2 ‚Üí Instances ‚Üí Launch Instance**

### 3Ô∏è‚É£ Name it something simple

`hope-training-gpu`

### 4Ô∏è‚É£ Choose OS

**Ubuntu 22.04 LTS (recommended)**

### 5Ô∏è‚É£ Choose instance type

Here pick ONE of these:

### ‚úî Best value (recommended)

* **g6e.xlarge** (L40S GPU, 48GB VRAM)

OR

### ‚úî Maximum performance

* **p4d.24xlarge** (8√ó A100, expensive, overkill)
* **p5.48xlarge** (H100, extremely expensive)

Pick the **g6e.xlarge** unless you are rich.

### 6Ô∏è‚É£ Storage

* Size: **200 GB gp3**

### 7Ô∏è‚É£ Create / download SSH key pair

You‚Äôll get a `.pem` file ‚Äî **DON‚ÄôT LOSE THIS**.

### 8Ô∏è‚É£ Launch the instance

Wait ~1 minute for it to initialize.

---

# ‚≠ê PART 2 ‚Äî Connect to your server (terminal)

On your local computer:

1. Move the key to a safe place (example):

```
~/aws_keys/mykey.pem
```

2. Restrict permissions:

```
chmod 600 ~/aws_keys/mykey.pem
```

3. Connect using SSH:

```
ssh -i ~/aws_keys/mykey.pem ubuntu@YOUR_EC2_PUBLIC_IP
```

Your terminal should now show:

```
ubuntu@ip-xx-xx-xx-xx:~$
```

You are inside your GPU server now.

---

# ‚≠ê PART 3 ‚Äî Install necessary software (copy/paste)

Paste these in order:

### 1Ô∏è‚É£ Update system

```
sudo apt update && sudo apt upgrade -y
```

### 2Ô∏è‚É£ Install essentials

```
sudo apt install -y git wget python3 python3-pip python3-venv
```

### 3Ô∏è‚É£ Install NVIDIA drivers (L40S already has correct ones)

```
sudo ubuntu-drivers install
sudo reboot
```

**Reconnect SSH after reboot**

### 4Ô∏è‚É£ Create Python virtual environment

```
python3 -m venv hope_env
source hope_env/bin/activate
```

### 5Ô∏è‚É£ Install PyTorch with CUDA 12

```
pip install torch==2.2.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 6Ô∏è‚É£ Install HuggingFace tools

```
pip install datasets transformers accelerate sentencepiece
```

### 7Ô∏è‚É£ Install tiktoken (your tokenizer)

```
pip install tiktoken
```

---

# ‚≠ê PART 4 ‚Äî Upload your project to the server

Two easy options:

---

## üìå OPTION A ‚Äî Upload via GitHub (recommended)

On EC2:

```
git clone https://github.com/YOUR_USERNAME/YOUR_REPO.git
cd YOUR_REPO
```

---

## üìå OPTION B ‚Äî Upload directly from your computer

From your local terminal:

```
scp -i ~/aws_keys/mykey.pem -r /path/to/your/project ubuntu@YOUR_EC2_PUBLIC_IP:/home/ubuntu/
```

This copies your entire project to the EC2 machine.

---

# ‚≠ê PART 5 ‚Äî Run your training

Make sure you‚Äôre inside the project directory:

```
cd /home/ubuntu/YOUR_PROJECT/Train_model
```

Activate your environment:

```
source ~/hope_env/bin/activate
```

Start training:

```
python train.py
```

You should immediately see logs like:

```
Using device: cuda
Step 0 | loss: ...
Compiling model...
Streaming dataset initialized...
```

---

# ‚≠ê PART 6 ‚Äî Monitor GPU usage

Open another terminal window and run:

```
ssh -i ~/aws_keys/mykey.pem ubuntu@YOUR_EC2_IP
watch -n 1 nvidia-smi
```

You should see:

* GPU at 90‚Äì100% usage
* VRAM around 20‚Äì40GB
* Temperature 70‚Äì80¬∞C

This means training is running correctly.

---

# ‚≠ê PART 7 ‚Äî Save your checkpoints

Your training script already saves checkpoints (if implemented).
You can download them anytime with:

```
scp -i ~/aws_keys/mykey.pem ubuntu@YOUR_EC2_IP:/home/ubuntu/YOUR_PROJECT/Train_model/checkpoints/* .
```

---

# ‚≠ê PART 8 ‚Äî VERY IMPORTANT ‚Äî Stop the instance when done

Otherwise AWS keeps charging money.

In AWS Console:

### EC2 ‚Üí Instances ‚Üí select instance ‚Üí Actions ‚Üí **Stop**

**Stop** = safe
**Terminate** = deletes disk + data

If you want checkpoints kept forever ‚Üí **STOP**, don‚Äôt terminate.

---
